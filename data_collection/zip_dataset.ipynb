{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`extract`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sign_language_translator as slt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "videos\n",
      "├── pk-hfad-1_چڑیا-گھر.mp4\n",
      "└── pk-hfad-1_گھر.mp4\n"
     ]
    }
   ],
   "source": [
    "slt.utils.Archive.extract(\"pk-hfad-1_video-mp4.zip\", \"*گھر.mp4\", \"datasets/videos\")\n",
    "slt.utils.tree(\"datasets/videos\", directory_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slt.Assets.extract(r\"videos/pk-hfad-1_[slt]\\(.*\\).mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slt.utils.Archive.create(\"xx-wordless-1_wordless.mp4\", \"xx-wordless-1_videos-mp4.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import sign_language_translator as slt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "move specific files to **temp_src** folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "788"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_dir = \"/Users/mudassar.iqbal/Library/CloudStorage/GoogleDrive-mdsriqb@gmail.com/My Drive/sign-language-translator/sign-language-datasets/sign_recordings/videos\"\n",
    "collection = \"pk-hfad-1\"\n",
    "person = \"person101\"\n",
    "camera = \"below\"\n",
    "\n",
    "pattern = os.path.join(raw_data_dir, collection, person, f\"*_{person}_{camera}.mp4\")\n",
    "raw_paths = glob(pattern)\n",
    "len(raw_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test file names\n",
    "slt.Assets.load_all_urls()\n",
    "\n",
    "base_names = {i.split(\"_\")[-1][:-4] for i in slt.Assets.get_ids(f\"videos/{collection}_.*mp4\")}\n",
    "read_names = {os.path.basename(p).split(\"_\")[0] for p in raw_paths}\n",
    "\n",
    "base_names == read_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"temp_src\", exist_ok=True)\n",
    "for p in (bar:=tqdm(raw_paths[:])):\n",
    "    word = os.path.basename(p).split(\"_\")[0]\n",
    "    new_person = (\"d\" if person[6]==\"1\" else \"h\") + (\"m\" if person[7]==\"0\" else \"f\") + f\"{int(person[8:]):04}\"\n",
    "    new_camera = camera # \"top-\"+camera # \"30x0y0z\"\n",
    "    new_name = f\"{collection}_{word}_{new_camera}_{new_person}\"\n",
    "    new_p = f\"temp_src/{new_name}.mp4\"\n",
    "    bar.set_description(os.path.basename(p))\n",
    "    bar.set_postfix_str(new_name)\n",
    "    shutil.copy2(p, new_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slt.utils.Archive.create(\"./pk-hfad-1_landmarks-mediapipep2h1-csv/*\", \"pk-hfad-1_landmarks-mediapipe-pose-2-hand-1-csv.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`make JSON from CSV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import sign_language_translator as slt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slt.utils.Archive.extract(\"../vision/pk-hfad-1_landmarks-mediapipep2h1-csv.zip\", \"*.csv\", \"datasets/landmarks\")\n",
    "\n",
    "json_data = {}\n",
    "for file in tqdm(glob(\"datasets/landmarks/pk-hfad-1_landmarks-mediapipep2h1-csv/*.csv\")):\n",
    "    json_data[os.path.basename(file).rsplit(\".csv\")[0]] = np.loadtxt(file, delimiter=\",\").tolist()\n",
    "\n",
    "with open(\"pk-hfad-1_landmarks-mediapipep2h1.json\", \"w\") as f:\n",
    "    json.dump(json_data, f)\n",
    "\n",
    "slt.utils.Archive.create(\"pk-hfad-1_landmarks-mediapipep2h1.json\", \"pk-hfad-1_landmarks-mediapipep2h1-json.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slt.utils.Archive.create(\"pk-hfad-1_landmarks-mediapipep2h1.json\", \"pk-hfad-1_landmarks-mediapipep2h1-json.zip\", overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
