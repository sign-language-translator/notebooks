{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenative Synthesis (Rule-Based Translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sign_language_translator as slt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = slt.models.ConcatenativeSynthesis(text_language=\"urdu\", sign_language=\"psl\", sign_format=\"vid\")\n",
    "# text = \"ایک سیب اچھا ہے۔\"\n",
    "text = \"یہ مگرمچھ نیلا ہے۔\"\n",
    "# text = \"تربوز لال ہے۔\"\n",
    "sentence = model.translate(text)\n",
    "sentence.show(inline_player=\"html5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.save(f\"outputs/{text}.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import jsonschema\n",
    "import numpy as np\n",
    "\n",
    "import sign_language_translator as slt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`configure dataset directory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./temp_dataset\"\n",
    "slt.Assets.set_root_dir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create vocabulary object`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our mapping datasets: https://github.com/sign-language-translator/sign-language-datasets/blob/main/parallel_texts\n",
    "# define mapping\n",
    "mapping_dataset = [\n",
    "    {\n",
    "        \"country\": \"xx\",\n",
    "        \"description\": \"custom sign language videos and corresponding words.\",\n",
    "        \"mapping\": [\n",
    "            {\n",
    "                \"label\": \"xx-yy-1_greeting\",\n",
    "                \"token\": {\n",
    "                    \"en\": [\"hello\", \"hey\",],\n",
    "                    \"hi\": [\"नमस्ते\"],\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"label\": \"xx-yy-1_world\",\n",
    "                \"token\": {\n",
    "                    \"en\": [\"world\", \"globe\", \"earth\",],\n",
    "                    \"ur\": [\"دنیا\"],\n",
    "                }\n",
    "            },\n",
    "        ],\n",
    "        \"organization\": \"yy\",\n",
    "        \"url\": \"https://www.example.com\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# validate the dataset format\n",
    "schema_path = slt.Assets.download(\"mapping-schema.json\")[0]\n",
    "with open(schema_path, 'r') as f:\n",
    "    jsonschema.validate(mapping_dataset, json.load(f))\n",
    "\n",
    "# store in data_dir so it can be retrieved whenever its needed\n",
    "with open(os.path.join(data_dir, \"xx-dictionary-mapping.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(mapping_dataset, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# read with our mapping dataset reader\n",
    "vocab = slt.languages.Vocab(\n",
    "    language=\"en\", country=\"xx\", organization=\"yy\", data_root_dir=data_dir, arg_is_regex=False\n",
    ")\n",
    "vocab.supported_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`demo videos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sign_language_translator as slt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local storage\n",
    "frames = np.zeros((10, 256, 256, 3), dtype=np.uint8) # (frames, height, width, channels)\n",
    "slt.Video(frames, fps=5).save(os.path.join(slt.Assets.ROOT_DIR, \"videos\", \"xx-yy-1_greeting.mp4\"))\n",
    "\n",
    "# hosted online (auto-downloaded when needed)\n",
    "slt.Assets.FILE_TO_URL.update({\"videos/xx-yy-1_world.mp4\": \"https://github.com/sign-language-translator/sign-language-datasets/releases/download/v0.0.2/wordless_wordless.mp4\"})\n",
    "\n",
    "# videos can also be stored inside zip archives (data_dir/datasets/xx-yy-1_videos-mp4.zip)\n",
    "# the needed videos will be extracted automatically to data_dir/videos\n",
    "# slt.Assets.download(...), slt.Assets.extract(...), slt.Assets.fetch(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create languages`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySignLang(slt.languages.SignLanguage):\n",
    "    pass\n",
    "\n",
    "class MyTextLang(slt.languages.TextLanguage):\n",
    "    pass\n",
    "\n",
    "# TODO: class MyEnglish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = slt.models.ConcatenativeSynthesis(\n",
    "    text_language=MyTextLang(),\n",
    "    sign_language=MySignLang(),\n",
    "    sign_format=\"video\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`translate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign = model.translate(\"Hello world!\")\n",
    "sign.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate (step-by-step)\n",
    "text = \"Hi earth.\"\n",
    "tokens = model.blah_blah_blah(text)\n",
    "sign_filenames = model.blah_blah(tokens)\n",
    "sign_list = model.blah(sign_filenames)\n",
    "sign = model.concatenate_signs(sign_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
