{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/slt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "from importlib import reload\n",
    "import sign_language_translator as slt\n",
    "reload(slt)\n",
    "slt.set_dataset_dir(\"/Users/mudassar.iqbal/Library/CloudStorage/GoogleDrive-mdsriqb@gmail.com/My Drive/sign-language-translator/sign-language-datasets\")\n",
    "\n",
    "from sign_language_translator.languages.sign import pakistan_sign_language, sign_language, mapping_rules\n",
    "from sign_language_translator.languages.text import urdu, Tags\n",
    "from sign_language_translator.languages import vocab\n",
    "from sign_language_translator.models.text_to_sign import concatenative_synthesis\n",
    "reload(sign_language)\n",
    "reload(pakistan_sign_language)\n",
    "reload(vocab)\n",
    "reload(mapping_rules)\n",
    "reload(urdu)\n",
    "reload(concatenative_synthesis)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vocab.Vocab(r\".*\", [r\"pk-hfad(-\\d+)?\"])\n",
    "psl = pakistan_sign_language.PakistanSignLanguage()\n",
    "ur = urdu.Urdu()\n",
    "t2s_model = concatenative_synthesis.ConcatenativeSynthesis(ur, psl, \"mp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " ' ',\n",
       " 'darkness',\n",
       " ' ',\n",
       " 'my',\n",
       " ' ',\n",
       " 'old(not-new-from-past)',\n",
       " ' ',\n",
       " 'friend',\n",
       " '!',\n",
       " ' ',\n",
       " '(',\n",
       " 'bye',\n",
       " ')']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sign_language_translator.text import SignTokenizer\n",
    "tok = SignTokenizer()\n",
    "\n",
    "text = \"hello darkness my old(not-new-from-past) friend! (bye)\"\n",
    "# tokens = tok.tokenize(text)\n",
    "tokens = tok.tokenize(text, join_word_sense=True)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens = ['this', ' ', 'is', ' ', 'door', ' ', '107', '.']\n",
      "tags = [Tags.WORD, Tags.SPACE, Tags.WORD, Tags.SPACE, Tags.WORD, Tags.SPACE, Tags.NUMBER, Tags.PUNCTUATION]\n",
      "r_tokens = ['this', 'door', '107']\n",
      "r_tags = [Tags.WORD, Tags.WORD, Tags.NUMBER]\n",
      "signs = \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'signs': [['pk-hfad-1_یہ']], 'weights': [1.0]},\n",
       " {'signs': [['pk-hfad-1_gate(noun)']], 'weights': [1.0]},\n",
       " {'signs': [['pk-hfad-1_10']], 'weights': [1.0]},\n",
       " {'signs': [['pk-hfad-1_7']], 'weights': [1.0]}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"this is door 107.\"\n",
    "\n",
    "tokens = ur.tokenize(sentence)\n",
    "tags = ur.get_tags(tokens)\n",
    "print(f\"{tokens = }\")\n",
    "print(f\"{tags = }\")\n",
    "\n",
    "r_tokens, r_tags, _ = psl.restructure_sentence(tokens, tags)\n",
    "print(f\"{r_tokens = }\")\n",
    "print(f\"{r_tags = }\")\n",
    "\n",
    "signs = psl.tokens_to_sign_dicts(r_tokens, r_tags)\n",
    "print(\"signs = \")\n",
    "signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tags.SUPPORTED_WORD, Tags.SPACE, Tags.SUPPORTED_WORD, Tags.SPACE, Tags.NAME, Tags.SPACE, Tags.NAME, Tags.SPACE, Tags.SUPPORTED_WORD, Tags.SPACE, Tags.SUPPORTED_WORD, Tags.SPACE, Tags.SUPPORTED_WORD, Tags.PUNCTUATION]\n",
      "['میں(i)', 'وزیراعظم', 'عمران', 'خان', 'کے(of)', 'گھر', 'گیا']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'signs': [['pk-hfad-1_میں(i)']], 'weights': [1.0]},\n",
       " {'signs': [['pk-hfad-1_a(double-handed-letter)',\n",
       "    'pk-hfad-1_a(double-handed-letter)',\n",
       "    'pk-hfad-1_a(double-handed-letter)'],\n",
       "   ['pk-hfad-1_وزیراعظم']],\n",
       "  'weights': [0.5, 0.5]},\n",
       " {'signs': [['pk-hfad-1_ع']], 'weights': [1.0]},\n",
       " {'signs': [['pk-hfad-1_m(single-handed-letter)']], 'weights': [1.0]},\n",
       " {'signs': [['pk-hfad-1_r(single-handed-letter)']], 'weights': [1.0]},\n",
       " {'signs': [['pk-hfad-1_a(single-handed-letter)']], 'weights': [1.0]},\n",
       " {'signs': [['pk-hfad-1_n(single-handed-letter)']], 'weights': [1.0]},\n",
       " {'signs': [['pk-hfad-1_خ']], 'weights': [1.0]},\n",
       " {'signs': [['pk-hfad-1_a(single-handed-letter)']], 'weights': [1.0]},\n",
       " {'signs': [['pk-hfad-1_n(single-handed-letter)']], 'weights': [1.0]},\n",
       " {'signs': [['pk-hfad-1_کے(of)']], 'weights': [1.0]},\n",
       " {'signs': [['pk-hfad-1_گھر']], 'weights': [1.0]},\n",
       " {'signs': [['pk-hfad-1_گیا']], 'weights': [1.0]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"میں(i) وزیراعظم عمران خان کے(of) گھر گیا۔\"\n",
    "tokens = ur.tokenize(text)\n",
    "tags = ur.get_tags(tokens)\n",
    "print(tags)\n",
    "tokens, tags, _ = psl.restructure_sentence(tokens, tags=tags)\n",
    "print(tokens)\n",
    "sign_dicts = psl.tokens_to_sign_dicts(tokens, tags=tags)\n",
    "sign_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('عمران(نام)', Tags.NAME)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ur.tag(ur.tokenize(\"عمران(نام)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pk-hfad-1_میں(i)',\n",
       " 'pk-hfad-1_a(double-handed-letter)',\n",
       " 'pk-hfad-1_a(double-handed-letter)',\n",
       " 'pk-hfad-1_a(double-handed-letter)',\n",
       " 'pk-hfad-1_ع',\n",
       " 'pk-hfad-1_m(single-handed-letter)',\n",
       " 'pk-hfad-1_r(single-handed-letter)',\n",
       " 'pk-hfad-1_a(single-handed-letter)',\n",
       " 'pk-hfad-1_n(single-handed-letter)',\n",
       " 'pk-hfad-1_خ',\n",
       " 'pk-hfad-1_a(single-handed-letter)',\n",
       " 'pk-hfad-1_n(single-handed-letter)',\n",
       " 'pk-hfad-1_کے(of)',\n",
       " 'pk-hfad-1_گھر',\n",
       " 'pk-hfad-1_گیا']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2s_model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sign_language_translator.text.utils import ListRegex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc', 'lmn', '123', '123']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\"abc\", \"lmn\", \"123\", \"123\", \"123\", \"xyz\", \"def\", \"pqr\"]\n",
    "span = ListRegex.match(\n",
    "    data,\n",
    "    [r\"(abc|cba)\", [r\"jk\",r\"lmno?\"], (\"123\", (0, 2))] # ! at-most 0 must not match any\n",
    ")\n",
    "data[span[0]:span[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hello', '(', 'word', '-', 'word', ')'], ['world', '(', 'sense', ')']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ListRegex.find_all(\n",
    "    [\"hello\", \"(\", \"word\", \"-\", \"word\", \")\", \"something\", \"somgething\", \"world\", \"(\", \"sense\", \")\", \".\"],\n",
    "    [r\"\\w+\", r\"\\(\", r\"\\w+\", ([r\"-\", r\"\\w+\"], (0, None)), r\"\\)\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
